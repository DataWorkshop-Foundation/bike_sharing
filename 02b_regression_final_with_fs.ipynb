{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Main info*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Project description:*** https://www.kaggle.com/competitions/bike-sharing-demand/overview/description\n",
    "\n",
    "***Project goal:*** combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.\n",
    "\n",
    "***Notebook goal:*** check integration of some simple feature selection techniques into previous notebook\n",
    "\n",
    "***Suggested evaluation metric:*** Root Mean Squared Logarithmic Error (RMSLE)\n",
    "\n",
    "***Other used evalutaion metrics*** Mean Absolute Error(MAE), Mean Squared Error(MSE), Root Mean Squared Error(RMSE), R Squared (R2)\n",
    "\n",
    "***Comment*** This notebook uses previous notebook: <u>02a_regression_top_datasets_and_models</u>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***0. Project preparation*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main upgrades\n",
    "!pip install --upgrade neptune-client\n",
    "!pip install --upgrade neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "import catboost as ctb\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "\n",
    "import eli5\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import neptune\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import re\n",
    "import pickle\n",
    "import heapq\n",
    "import inspect\n",
    "\n",
    "# minor settings\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "set_config(display='diagram')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# global variables\n",
    "RANDOM_STATE = 0\n",
    "OUTPUT_DIR = 'outputs/'\n",
    "MODELS_DIR = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.5\n",
      "numpy...............1.20.0\n",
      "pandas..............1.2.4\n",
      "sklearn.............0.24.2\n",
      "eli5................0.11.0\n",
      "neptune.............0.15.2\n",
      "catboost............0.25.1\n",
      "lightgbm............3.0.0\n",
      "xgboost.............1.3.2\n"
     ]
    }
   ],
   "source": [
    "# version check\n",
    "def show_version(module_object: object, n: int = 20) -> str:\n",
    "    '''\n",
    "    Check version of different libraries\n",
    "    '''\n",
    "    module_name = getattr(module_object, '__name__')\n",
    "    module_ver = getattr(module_object, '__version__')\n",
    "    dots = '.' * (n - len(module_name))\n",
    "    \n",
    "    print (f'{module_name}{dots}{module_ver}')\n",
    "\n",
    "\n",
    "!python --version\n",
    "module_list = [np, pd, sklearn, eli5, neptune, ctb, lgbm, xgb]\n",
    "for module in module_list:\n",
    "    show_version(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run neptune server\n",
    "def init_neptune(credentials_file = 'neptune_credentials.json'):\n",
    "    '''\n",
    "    Initialize neptune project\n",
    "    '''\n",
    "    with open(credentials_file) as f:\n",
    "        neptune_credentials = json.load(f)\n",
    "\n",
    "    run = neptune.init(\n",
    "        api_token = neptune_credentials['API_TOKEN'],\n",
    "        project_qualified_name = neptune_credentials['PROJECT']\n",
    "    )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***1. Load data*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('inputs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict = {1: ['Clear', 'Few clouds', 'Partly cloudy'],\n",
    "2: ['Mist + Cloudy', 'Mist + Broken clouds', 'Mist + Few clouds', 'Mist'],\n",
    "3: ['Light Snow', 'Light Rain + Thunderstorm + Scattered clouds', 'Light Rain + Scattered clouds'],\n",
    "4: ['Heavy Rain + Ice Pallets + Thunderstorm + Mist', 'Snow + Fog']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***2. Custom data classes*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer():\n",
    "    '''\n",
    "    Change the initial dataset into a new one based\n",
    "    on passed function\n",
    "    '''\n",
    "    # copy parameter introduced to prevent SettingwithCopyWarning\n",
    "    # https://www.dataquest.io/blog/settingwithcopywarning/\n",
    "    def __init__(self, func, copy = True, **kwargs):\n",
    "        self.func = func\n",
    "        self.copy = copy\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df_ = input_df if not self.copy else input_df.copy()\n",
    "        return self.func(input_df_,)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector():\n",
    "    '''\n",
    "    Return a dataframe with predefined columns only\n",
    "    '''\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        cpy_df = X[self.columns].copy()\n",
    "        return cpy_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDroper():\n",
    "    '''\n",
    "    Return a dataframe without selected columns\n",
    "    '''\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***3. Custom feature functions*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.1. Add or change functions*** ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.1.1. Numerical features functions*** ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1.1 Main transformation functions #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_columns(dataset: pd.DataFrame, feats: list, transformer: sklearn.preprocessing._data) -> pd.DataFrame:\n",
    "    '''\n",
    "    Use a transformer to transform selected columns\n",
    "    Examples of transformers: OrdinalEncoder, MinMaxScaler, Normalizer, StandardScaler\n",
    "        Function used in pipeline step.\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dataframe with transformed columns\n",
    "    '''\n",
    "    dataset[feats] = transformer.fit_transform(dataset[feats])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dataset: pd.DataFrame, pipeline: Pipeline) -> pd.DataFrame:\n",
    "    '''\n",
    "    Return a dataset after pipeline transformations.\n",
    "        Function used in main run step.\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "\n",
    "    Returns: \n",
    "        dataset after pipeline transformation\n",
    "    '''\n",
    "    return pipeline.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1.2 Other transformation functions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cols_from_datetime(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Convert a column to datetime format and create new columns: \n",
    "    'year', 'month', 'day', 'hour'\n",
    "    \n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame \n",
    "    \n",
    "    Returns:\n",
    "        dataset: transformed pandas DataFrame\n",
    "    '''\n",
    "\n",
    "    # convert string to datetime type\n",
    "    dataset['datetime'] = pd.to_datetime(dataset['datetime'])\n",
    "\n",
    "    # make new columns from datetime column\n",
    "    dataset['year'] = dataset['datetime'].dt.year\n",
    "    dataset['month'] = dataset['datetime'].dt.month\n",
    "    dataset['day'] = dataset['datetime'].dt.day\n",
    "    dataset['hour'] = dataset['datetime'].dt.hour\n",
    "    dataset['dayofweek'] = dataset['datetime'].dt.dayofweek\n",
    "    dataset['weekend'] = dataset['dayofweek'].map(lambda x: int(x in [6,7]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasons_change(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Set proper season duration and change their representation according\n",
    "    to dataset legend\n",
    "\n",
    "    Argument:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        dataset: pandas DataFrame\n",
    "    '''\n",
    "\n",
    "    changes = [\n",
    "    ('2011-01-01', '2011-03-19', 4),\n",
    "    ('2011-03-20', '2011-06-20', 1),\n",
    "    ('2011-06-21', '2011-09-22', 2),\n",
    "    ('2011-09-23', '2011-12-20', 3),\n",
    "    ('2011-12-21', '2012-03-19', 4),\n",
    "    ('2012-03-20', '2012-06-19', 1),\n",
    "    ('2012-06-20', '2012-09-21', 2),\n",
    "    ('2012-09-22', '2012-12-20', 3),\n",
    "    ('2012-12-21', '2012-12-31', 4),\n",
    "     ]\n",
    "\n",
    "    for (start_date, end_date, new_season) in changes:\n",
    "        dataset.loc[between_dates(dataset, start_date, '00', end_date, '23').index,'season'] = new_season\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agg_features(dataset: pd.DataFrame, agg_name = np.median) -> pd.DataFrame:\n",
    "    '''\n",
    "    Calculate a monthly agg_function (like mean, median...) and add it to the dataframe\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        dataset: DataFrame with an additional column which contains the agg_function\n",
    "        of bike shares in a month\n",
    "    '''\n",
    "    agg_dataset = dataset[['month', 'year', 'count']].groupby(['month', 'year']).agg(agg_name)\n",
    "    agg_dataset = agg_dataset.reset_index()\n",
    "    agg_dataset = agg_dataset.rename(columns = {'count':str(agg_name.__name__)})\n",
    "    return pd.merge(dataset, agg_dataset, on=['month', 'year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize_feats(dataset: pd.DataFrame, feats: list = []) -> pd.DataFrame:\n",
    "    '''\n",
    "    Normalize selected features. Equivalent of MinMaxScaler\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        dataset: pandas DataFrame\n",
    "    '''\n",
    "    for feature_name in feats:\n",
    "        if feature_name in dataset.columns.tolist():\n",
    "            max_value = dataset[feature_name].max()\n",
    "            min_value = dataset[feature_name].min()\n",
    "            dataset[feature_name] = (dataset[feature_name] - min_value) / (max_value - min_value)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_y_pred(y_pred: np.array) -> np.array:\n",
    "    '''\n",
    "    Correct y_pred values co they don't contain any negative values\n",
    "        Function used in main run step.\n",
    "\n",
    "    Arguments:\n",
    "        y_pred: np.array\n",
    "    \n",
    "    Returns:\n",
    "        y_pred: array wiht no negative values; every negative value\n",
    "        is replaced with median\n",
    "    '''\n",
    "    df_median = np.median(df_train['count']) \n",
    "    y_pred = [df_median if y<0 else y for y in y_pred] \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.1.2. Text (nlp) features functions*** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_weather(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Change integers in 'weather' column (1, 2, 3, ...) into a list of weather\n",
    "    phenomena\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        initial dataframe with one extra column (weather_phenomena)\n",
    "    '''\n",
    "    \n",
    "    # split weather phenomena into individual elements\n",
    "    def weather_to_indicidual(x):\n",
    "        x = ','.join([elem for elem in x])\n",
    "        x = re.split(r'[,\\+]', x)\n",
    "\n",
    "        return list(set([elem.strip() for elem in x]))\n",
    "\n",
    "    # change integers in 'weather' column  into list of individual weather phenomena\n",
    "    dataset['weather_phenomena'] = dataset['weather'].map(weather_dict).apply(lambda x: weather_to_indicidual(x))\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconstruct_weather_tokens(dataset: pd.DataFrame, token_col_name: str = 'weather_phenomena') -> pd.DataFrame:\n",
    "    '''\n",
    "    One-hot-encode individual weather phenomena and add them to initial dataframe\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        initial dataframe with an extra columns containing 0 or 1; each column\n",
    "        represents an individual weather phenomena\n",
    "    '''\n",
    "\n",
    "    # make a list of all individual meteorological phenomena \n",
    "    all_phenomena = list(dataset[token_col_name].explode().unique())\n",
    "\n",
    "    def return_cols_with_individual_phenomena(phenomena: pd.Series) -> pd.DataFrame:\n",
    "        '''\n",
    "        Build a dataframe (X) with all_phenomena as columns and put 0 or 1 in \n",
    "        rows representing the presence or absence of a particular phenomena\n",
    "        '''\n",
    "\n",
    "        def phenomenon_in_phenomena(phenomena: pd.Series) -> list:\n",
    "            return [int(phenomenon in phenomena) for phenomenon in all_phenomena]\n",
    "    \n",
    "        X = phenomena.map(phenomenon_in_phenomena).apply(pd.Series)\n",
    "        X.columns = all_phenomena\n",
    "        return X \n",
    "    \n",
    "    X = return_cols_with_individual_phenomena(dataset['weather_phenomena'])\n",
    "\n",
    "    # concatenate columns to original dataset\n",
    "    return pd.concat([dataset, X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weather_embeddings(dataset: pd.DataFrame) -> np.array:\n",
    "    '''\n",
    "    Return unique vector representations of the weather column\n",
    "        Function needed for vectorize_weather_nlp function\n",
    "    \n",
    "    Arguments: \n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        array of 4 lists (4 types of weather), each list containing 384 elements\n",
    "    '''\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # randomly chosen pretrained model\n",
    "    model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "\n",
    "    # column of unique meteo phenomena in a 'str' form\n",
    "    uni_meteo_weather = dataset['weather_phenomena'].map(lambda x: ' '.join(x)).unique() \n",
    "\n",
    "    # vector representatnions of 'uni_meteo_weather'\n",
    "    embeddings = model.encode(uni_meteo_weather, convert_to_tensor = False)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_weather_nlp(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Return vector representations of the weather column\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        dataset with 384 more columns containing vector representation of sentences\n",
    "        (meteorological phenomena contatenated into a string are treated as sentences)\n",
    "    '''\n",
    "\n",
    "    # unique integers (1, 2, 3, 4) repesenting the weather\n",
    "    uni_num_weather = dataset['weather'].unique()\n",
    "    \n",
    "    # unique embeddings of weather phenomena\n",
    "    embeddings = make_weather_embeddings(dataset)\n",
    "\n",
    "    # dictionary for pandas mapping\n",
    "    embeddings_dict = dict(zip(uni_num_weather, embeddings))\n",
    "\n",
    "    # one additional column containing a 384-element list in each cell\n",
    "    dataset['weather_embeddings'] = dataset['weather'].map(embeddings_dict)\n",
    "\n",
    "    # split 'weather_embeddings' into 384 individual columns and concat them to the original dataset\n",
    "    dataset = pd.concat([dataset, pd.DataFrame(dataset['weather_embeddings'].tolist())], axis = 1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cos_sim_weather(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Calculate cosinus similarity between 4 weather types and concat\n",
    "    4 additional columns to the original dataset containing calculated\n",
    "    similarity\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        original dataset with 4 extra columns representing cosine similarity \n",
    "        between weather types\n",
    "    '''\n",
    "\n",
    "    # construct 4x4 array of cosine similarity\n",
    "    cos_sims_array = peek_weather_cos_sim(dataset, return_dataframe= False)\n",
    "\n",
    "    # dictionary with cos_sims for pandas mapping \n",
    "    # {1: [1.000000 0.897642 0.728108 0.566511], 2: [...], 3: [...], 4: [...]}\n",
    "    cos_sims_dict = dict(zip(list(range(1,5)), cos_sims_array))\n",
    "\n",
    "    # map dictionary to pandas DataFrame as a new column\n",
    "    dataset['cos_sims'] = dataset['weather'].map(cos_sims_dict)\n",
    "\n",
    "    # deconstruct mapped column to 4 individual columns\n",
    "    cos_sims_new_columns = pd.DataFrame(dataset['cos_sims'].tolist(), columns = [f'cos_sim_weather_{n}' for n in list(range(1, 5))])\n",
    "\n",
    "    # delete not needed column\n",
    "    del dataset['cos_sims']\n",
    "\n",
    "    return pd.concat([dataset, cos_sims_new_columns], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.2. Select functions*** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_dates(dataset: pd.DataFrame, start_date: str, start_time: str, end_date: str, end_time: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Show dataframe between two dates and timestamps\n",
    "    \n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame \n",
    "        start_date: date which the dataset must be trimmed from\n",
    "        start_time: hour of day from start_date\n",
    "        end_date: date which the dataset must be trimmed to\n",
    "        end_time: hour of day from end_date\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame between (start_date, start_time) and (end_date, end_time)\n",
    "    '''\n",
    "\n",
    "    start_dt = f'{start_date} {start_time}:00:00'\n",
    "    end_dt = f'{end_date} {end_time}:00:00'\n",
    "    mask = (dataset['datetime'] >= start_dt) & (dataset['datetime'] <= end_dt)\n",
    "    return dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_obvious(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Return a dataset withouth some obviously unneeded columns\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        dataset: pandas DataFrame\n",
    "    '''\n",
    "    black_list = ['Unnamed: 0', 'datetime', 'casual', 'registered']\n",
    "    \n",
    "    feats = [feat for feat in dataset.columns.tolist() if feat not in black_list]\n",
    "\n",
    "    return dataset[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dtypes(dataset: pd.DataFrame, dtypes = np.number) -> pd.DataFrame:\n",
    "    '''\n",
    "    Return a dataset with a specific datatype\n",
    "\n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        dataset: pandas DataFrame\n",
    "    '''\n",
    "    return dataset.select_dtypes(include=dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_y(dataset: pd.DataFrame, test_size: int = 0.3):\n",
    "    '''\n",
    "    Split dataframe info train and valid set\n",
    "    \n",
    "    Arguments:\n",
    "        dataset: pandas DataFrame\n",
    "        test_size: test size split\n",
    "    \n",
    "    Returns:\n",
    "        two DataFrames and two DataSeries containing independent and target variables\n",
    "    '''\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataset.drop('count', axis = 1), dataset['count'], test_size = test_size, random_state = RANDOM_STATE)\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_results_files(models_df: pd.DataFrame, topn: int = 5, metric: str = 'score_rmsle', lower_is_better: bool = True) -> list :\n",
    "    '''\n",
    "    Return a tuple containing file names with best n models and datasets\n",
    "\n",
    "    Arguments:\n",
    "        models_df: dataframe of models after main run loop\n",
    "        topn: how many top models are being returned\n",
    "        metric: evaluation metric which is being taken into account when choosing top models\n",
    "        lower_is_better: specify is a lower value of metric means a better model performence\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples; each tuple consist of a csv file name and a file model name\n",
    "        example: [(dataset1.csv, xgboost.model), (dataset1.csv, catboost.model), (dataset2.csv, xgboost.model)]\n",
    "    '''\n",
    "    if lower_is_better:\n",
    "        best_models = models_df.sort_values(by='score_rmsle', ascending= True).head(topn)\n",
    "    else:\n",
    "        best_models =models_df.sort_values(by='score_rmsle', ascending= False).head(topn)\n",
    "    \n",
    "    return [(f'{pipeline_name}.csv', f'{model_name}-{pipeline_name}.model') for pipeline_name, model_name in zip(best_models['pipeline_name'], best_models['model_custom_name'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_results_df(models_df: pd.DataFrame, topn: int = 5, metric: str = 'score_rmsle', lower_is_better: bool = True) -> pd.DataFrame:\n",
    "    '''\n",
    "    Return a dataframe with best n experiments\n",
    "\n",
    "    Arguments:\n",
    "        models_df: dataframe of models after main run loop\n",
    "        topn: how many top models are being returned\n",
    "        metric: evaluation metric which is being taken into account when choosing top models\n",
    "        lower_is_better: specify is a lower value of metric means a better model performence\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe trimmed to only  topn experiments base on a dataframe generated\n",
    "        with the run_experiments function\n",
    "    '''\n",
    "    if lower_is_better:\n",
    "        best_models = models_df.sort_values(by='score_rmsle', ascending= True).head(topn)\n",
    "    else:\n",
    "        best_models =models_df.sort_values(by='score_rmsle', ascending= False).head(topn)\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.3. Additional functions*** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek_weather_cos_sim(dataset: pd.DataFrame, return_dataframe = True):\n",
    "    '''\n",
    "    Show cosine similarity between different types of weather for a transformed dataset\n",
    "        Function needed for add_cos_sim_weather function\n",
    "    \n",
    "    Arguments: \n",
    "        dataset: pandas DataFrame (transformed dataset containing 'weather_phenomena' column)\n",
    "    \n",
    "    Returns:\n",
    "       4 x 4 DataFrame with cosine similarity of weather types \n",
    "       or\n",
    "       dataframe with cosine similarity of weather types\n",
    "        \n",
    "    '''\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "    # unique embeddings of weather phenomena    \n",
    "    embeddings = make_weather_embeddings(dataset)\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    cos_sims = cosine_similarity(embeddings)\n",
    "\n",
    "    # how many different weather types there is\n",
    "    no_weather_types = len(weather_dict)\n",
    "\n",
    "    if return_dataframe:\n",
    "        return  pd.DataFrame(cos_sims, columns = list(range(1,no_weather_types + 1)), index = list(range(1,no_weather_types + 1)))\n",
    "    else:\n",
    "        return cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(dataset: pd.DataFrame, pipeline: Pipeline, model, feats: list, metric, show_feature_importance: bool = True) -> tuple:\n",
    "    '''\n",
    "    Make a single prediction for a single case. This is needed when we want to quickly:\n",
    "    1) transform 2) split into train and valid 3) fit 4) predict 5) score\n",
    "    a dataset and a model\n",
    "\n",
    "    If a pipeline is specified the data will be transformed according to this pipeline, otherwise\n",
    "    an already prepared dataset must be provided as input.\n",
    "\n",
    "    If feats are provided, the dataset is restricted to only those feats. We can skip specifying\n",
    "    the feets if a pipeline already transformed the data properly to just the feats we want.\n",
    "\n",
    "    Arguments:\n",
    "        dataset: raw or transformed dataset\n",
    "        pipeline: pipeline to transform the dataset (optional)\n",
    "        model: specified model for fitting the dataset\n",
    "        feats: features to be included in a dataset (optional)\n",
    "        metric: metric for scoring\n",
    "    Returns:\n",
    "        transformed dataset, dictionary with model scores and params\n",
    "    '''\n",
    "\n",
    "    if pipeline is not None:\n",
    "        dataset = transform_dataset(dataset, pipeline)\n",
    "\n",
    "    if feats is not None:\n",
    "        X_train, X_valid, y_train, y_valid = make_X_y(dataset[feats])\n",
    "    else:\n",
    "        X_train, X_valid, y_train, y_valid = make_X_y(dataset)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_valid) \n",
    "    y_pred = correct_y_pred(y_pred)\n",
    "\n",
    "    # score = metric(y_valid, y_pred)\n",
    "    score_mae = mean_absolute_error(y_valid, y_pred)\n",
    "    score_mse = mean_squared_error(y_valid, y_pred)\n",
    "    score_rmse = np.sqrt(score_mse) \n",
    "    score_rmsle = rmsle(y_valid, y_pred)\n",
    "    score_r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "    model_params = str(model.get_params()) # model parameters\n",
    "    \n",
    "    # dictionary of all variables that are supposed to be logged\n",
    "    param_dict = {\n",
    "        'model': model.__class__.__name__,\n",
    "        'model_params': model_params,\n",
    "        'score_mae': score_mae,\n",
    "        'score_mse': score_mse,\n",
    "        'score_rmse': score_rmse,\n",
    "        'score_rmsle': score_rmsle,\n",
    "        'score_r2': score_r2,\n",
    "        'time_elapsed': end_time - start_time}\n",
    "\n",
    "    return display(dataset), param_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_results_files(filename: str, models_df):\n",
    "    '''\n",
    "    Save datasets names and models names to a *.npy file\n",
    "\n",
    "    Arguments:\n",
    "        filename: specified file name \n",
    "        models_df: dataset with summary of all models performence\n",
    "    '''\n",
    "    np.save(filename, np.array(top_results_files(models_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_eli5(model, feats):\n",
    "    results = eli5.explain_weights(model, feature_names = feats, top = None)\n",
    "    results_html = eli5.show_weights(model, feature_names = feats)\n",
    "\n",
    "    eli5_df = eli5.formatters.as_dataframe.format_as_dataframe(results)\n",
    "    eli5_dict = dict(zip(eli5_df['feature'], eli5_df['weight']))\n",
    "\n",
    "    sorted_weights = [(feat[0], feat[1]) for feat in sorted(eli5_dict.items(), key=lambda x: x[1], reverse = True)]\n",
    "\n",
    "    return results_html, sorted_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***4. Evaluation metrics*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    '''\n",
    "    The Root Mean Squared Log Error (RMSLE) metric \n",
    "\n",
    "    Arguments: \n",
    "        y_true: the ground truth labels given in the dataset\n",
    "        y_pred: our predictions\n",
    "        \n",
    "    Returns: \n",
    "        The RMSLE score\n",
    "    '''\n",
    "\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***5. Pipelines and models*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_pipeline = Pipeline(steps = [\n",
    "    ('drop obvious', DataTransformer(drop_obvious))\n",
    "], verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_preprocess = Pipeline(steps = [\n",
    "    ('make_dt_columns', \n",
    "                        DataTransformer(make_cols_from_datetime)),\n",
    "    ('change_seasons', \n",
    "                        DataTransformer(seasons_change)),\n",
    "    ('add_means', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.mean))),\n",
    "    ('add_medians', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.median))),\n",
    "    ('min_max_scale', \n",
    "                        DataTransformer(lambda df: transform_columns(df, ['atemp'], MinMaxScaler()))),\n",
    "    ('drop_obvious', \n",
    "                        DataTransformer(drop_obvious)),\n",
    "    ('dummies', \n",
    "                        DataTransformer(lambda df: pd.get_dummies(df, columns = ['season']))),\n",
    "    ('tokenize_weather',\n",
    "                        DataTransformer(tokenize_weather)),\n",
    "    ('deconstruct_tokens',\n",
    "                        DataTransformer(deconstruct_weather_tokens)),\n",
    "    ('nlp',\n",
    "                        DataTransformer(vectorize_weather_nlp)),\n",
    "    ('add_cos_sim',\n",
    "                        DataTransformer(add_cos_sim_weather)),\n",
    "    ('drop_columns', \n",
    "                        ColumnDroper(['weather_phenomena', 'weather_embeddings', 'humidity', 'windspeed', 'temp'])),\n",
    "], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nlp_pipeline = Pipeline(steps = [\n",
    "    ('make_dt_columns', \n",
    "                        DataTransformer(make_cols_from_datetime)),\n",
    "    ('change_seasons', \n",
    "                        DataTransformer(seasons_change)),\n",
    "    ('add_means', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.mean))),\n",
    "    ('add_medians', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.median))),\n",
    "    ('min_max_scale', \n",
    "                        DataTransformer(lambda df: transform_columns(df, ['atemp'], MinMaxScaler()))),\n",
    "    ('drop_obvious', \n",
    "                        DataTransformer(drop_obvious)),\n",
    "    ('dummies', \n",
    "                        DataTransformer(lambda df: pd.get_dummies(df, columns = ['season']))),\n",
    "    ('tokenize_weather',\n",
    "                        DataTransformer(tokenize_weather)),\n",
    "    ('deconstruct_tokens',\n",
    "                        DataTransformer(deconstruct_weather_tokens)),\n",
    "    ('add_cos_sim',\n",
    "                        DataTransformer(add_cos_sim_weather)),\n",
    "    ('drop_columns', \n",
    "                        ColumnDroper(['weather_phenomena', 'humidity', 'windspeed', 'temp'])),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nlp_pipeline_no_cos_sim = Pipeline(steps = [\n",
    "    ('make_dt_columns', \n",
    "                        DataTransformer(make_cols_from_datetime)),\n",
    "    ('change_seasons', \n",
    "                        DataTransformer(seasons_change)),\n",
    "    ('add_means', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.mean))),\n",
    "    ('add_medians', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.median))),\n",
    "    ('min_max_scale', \n",
    "                        DataTransformer(lambda df: transform_columns(df, ['atemp'], MinMaxScaler()))),\n",
    "    ('drop_obvious', \n",
    "                        DataTransformer(drop_obvious)),\n",
    "    ('dummies', \n",
    "                        DataTransformer(lambda df: pd.get_dummies(df, columns = ['season']))),\n",
    "    ('tokenize_weather',\n",
    "                        DataTransformer(tokenize_weather)),\n",
    "    ('deconstruct_tokens',\n",
    "                        DataTransformer(deconstruct_weather_tokens)),\n",
    "    ('drop_columns', \n",
    "                        ColumnDroper(['weather_phenomena', 'humidity', 'windspeed', 'temp'])),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_dummies_different_scaler = Pipeline(steps = [\n",
    "    ('make_dt_columns', \n",
    "                        DataTransformer(make_cols_from_datetime)),\n",
    "    ('change_seasons', \n",
    "                        DataTransformer(seasons_change)),\n",
    "    ('add_means', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.mean))),\n",
    "    ('add_medians', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.median))),\n",
    "    ('standard_scale', \n",
    "                        DataTransformer(lambda df: transform_columns(df, ['atemp'], StandardScaler()))),\n",
    "    ('drop_obvious', \n",
    "                        DataTransformer(drop_obvious)),\n",
    "    ('dummies', \n",
    "                        DataTransformer(lambda df: pd.get_dummies(df, columns = ['season', 'weather']))),\n",
    "    ('drop_columns', \n",
    "                        ColumnDroper(['humidity', 'windspeed', 'temp'])),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drop_humidity_windspeed_temp = Pipeline(steps = [\n",
    "    ('make_dt_columns', \n",
    "                        DataTransformer(make_cols_from_datetime)),\n",
    "    ('change_seasons', \n",
    "                        DataTransformer(seasons_change)),\n",
    "    ('add_means', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.mean))),\n",
    "    ('add_medians', \n",
    "                        DataTransformer(lambda df: generate_agg_features(df, np.median))),\n",
    "    ('standard_scale', \n",
    "                        DataTransformer(lambda df: transform_columns(df, ['atemp', 'temp', 'windspeed', 'humidity'], StandardScaler()))),\n",
    "    ('dummies', \n",
    "                        DataTransformer(lambda df: pd.get_dummies(df, columns = ['season', 'weather']))),\n",
    "    ('drop_obvious', \n",
    "                        DataTransformer(drop_obvious)),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xparams = {'n_estimators': 100, 'max_depth': 10, 'random_state': RANDOM_STATE, 'verbosity':0, 'use_label_encoder': False }\n",
    "xparams_more_n = {'n_estimators': 200, 'max_depth': 10, 'random_state': RANDOM_STATE, 'verbosity':0, 'use_label_encoder': False }\n",
    "cparams = {'n_estimators': 100, 'max_depth': 10, 'random_state': RANDOM_STATE , 'silent': True}\n",
    "lparams = {'n_estimators': 100, 'max_depth': 10, 'random_state': RANDOM_STATE, 'verbosity':-1, 'silent': True}\n",
    "lparams_more_depth = {'n_estimators': 100, 'max_depth': 20, 'random_state': RANDOM_STATE, 'verbosity':-1, 'silent': True}\n",
    "rfparams = {'random_state': RANDOM_STATE}\n",
    "dparams = {'strategy': 'median'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    ('basic_pipeline', basic_pipeline, 'No transfomations (other then essential drop columns'),\n",
    "    ('main_preprocess', main_preprocess, 'Default preprocess pipeline with nlp and with \"humidity\", \"casual\", \"windspeed\" columns dropped'),\n",
    "    ('no_nlp', no_nlp_pipeline, 'Same as default pipeline but with no nlp functions with \"humidity\", \"casual\", \"windspeed\" columns dropped'),\n",
    "    ('no_nlp_no_cos_sim', no_nlp_pipeline_no_cos_sim, 'Same as deafult pipeline but with no nlp and no cos_sim with \"humidity\", \"casual\", \"windspeed\" columns dropped'),\n",
    "    ('more_dummies_different_scaler_no_nlp', more_dummies_different_scaler, 'No nlp, no cos sim, dummies include: season and weather with \"humidity\", \"casual\", \"windspeed\" columns dropped'),\n",
    "    ('more_dummies_different_scaler_no_nlp_keep_3variables', no_drop_humidity_windspeed_temp, 'No nlp, no cos sim, dummies include: season and weather; \"humidity\", \"casual\", \"windspeed\" not dropped but scaled'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('XGBoostRegressor_100_estim', xgb.XGBRegressor(**xparams)),\n",
    "    ('XGBoostRegressor_200_estim', xgb.XGBRegressor(**xparams_more_n)),\n",
    "    ('CatBoostRregressor',  ctb.CatBoostRegressor(**cparams)),\n",
    "    ('LGBMRegressor_max_depth_10', lgbm.LGBMRegressor(**lparams)),\n",
    "    ('LGBMRegressor_max_depth_20', lgbm.LGBMRegressor(**lparams_more_depth)),\n",
    "    ('RandomForest', RandomForestRegressor()),\n",
    "    # ('DummyRegressor', DummyRegressor(**dparams)), #eli5 doesn't support dummy models\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***6. Feature selection methods*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectVarianceThreshold(dataset, threshold = 0.2):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel_var = sel.fit_transform(dataset)\n",
    "    sel_loc_index = sel.get_support(indices=True)\n",
    "\n",
    "    return list(dataset.columns[sel_loc_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_feats(dataset, k = 10):\n",
    "    fvalue_selector = SelectKBest(f_classif, k)\n",
    "    X_train, X_valid, y_train, y_valid = make_X_y(dataset)\n",
    "    kbest_anova = fvalue_selector.fit(X_train, y_train)\n",
    "    anova_feats = [feat for feat in list(kbest_anova.get_support()*X_valid.columns) if feat !='']\n",
    "\n",
    "    if 'count' not in anova_feats:\n",
    "        anova_feats += ['count']\n",
    "    \n",
    "    return anova_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_methods = [\n",
    "    (anova_feats, [2, 4, 6, 8, 10, 12, 14]),\n",
    "    (selectVarianceThreshold, [0.1, 0.2, 0.3]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***7. Main run*** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IMPORTANT`\n",
    "\n",
    "If you want to use feature selection (`use_fs = True`) then `pickle_models` must be set to `True`. Use `dump_pickled_models_to_neptune` with caution. It can send hundreds of MB of pickled models to neptune server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(pipelines, models = models, experiments_common_name = 'test-experiments', use_fs = False, use_neptune = True, pickle_models = False, dump_pickled_models_to_neptune = False):\n",
    "    \n",
    "    # empty dataframe for locally keeping track of results\n",
    "    models_df = pd.DataFrame()\n",
    "    models_heap = list()\n",
    "\n",
    "    # total number of all experiments\n",
    "    no_experiments = len(list(product(pipelines, models)))\n",
    "\n",
    "    print(f'Running {no_experiments} experiments')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    # initialize neptune if needed\n",
    "    if use_neptune:\n",
    "        run = init_neptune()\n",
    "    \n",
    "\n",
    "    e = 1 # first experiment number\n",
    "    for p, pipeline_obj in enumerate(pipelines, 1):\n",
    "        pipeline_name = pipeline_obj[0] # name of pipeline\n",
    "        pipeline = pipeline_obj[1] # pipeline instance\n",
    "        pipeline_comment = pipeline_obj[2] # pipeline description\n",
    "\n",
    "        print(f'Transforming dataset using |{pipeline_name}|... (transformation {p}/{len(pipelines)})')\n",
    "        print(f'{\"=\"*60}')\n",
    "\n",
    "        # Data transformation\n",
    "        df = transform_dataset(df_train, pipeline) # transform dataset using a pipeline\n",
    "        X_train, X_valid, y_train, y_valid = make_X_y(df) # split dataset into train and valid\n",
    "        \n",
    "        # Model application on transformed data \n",
    "        for m, model_object in enumerate(models, 1):\n",
    "\n",
    "            model_name = model_object[0] # custom name of a  model (like 'XGBoostRegressor')\n",
    "            model = model_object[1] # model instance\n",
    "\n",
    "            print('\\n')\n",
    "            print(f'Fitting... (model {m}/{len(models)})')\n",
    "            print(model_name)\n",
    "        \n",
    "            if use_neptune:\n",
    "                neptune.create_experiment(f'{experiments_common_name}-{e}') # name of experiment\n",
    "            \n",
    "            e += 1\n",
    "            start_time = time.time() # time fitting\n",
    "            model.fit(X_train, y_train) # fit the model\n",
    "            end_time = time.time()\n",
    "\n",
    "            # file pickling\n",
    "            if pickle_models: \n",
    "                \n",
    "                # file names\n",
    "                data_file_name = f'{pipeline_name}.csv'\n",
    "                model_file_name = f'{model_name}-{pipeline_name}.model'\n",
    "\n",
    "                if 'Unnamed: 0' in df.columns: del df['Unnamed: 0']\n",
    "                df.to_csv(f'{OUTPUT_DIR}{data_file_name}') # save dataframe locally\n",
    "                \n",
    "                # save model locally\n",
    "                with open(f'{MODELS_DIR}{model_file_name}', 'wb') as f:\n",
    "                    pickle.dump(model, f) # pickle a model\n",
    "                \n",
    "                if use_neptune and dump_pickled_models_to_neptune:\n",
    "                    # if specified dump pickled files to neptune\n",
    "                    neptune.log_artifact(f'{MODELS_DIR}{model_file_name}')\n",
    "                    neptune.log_artifact(f'{OUTPUT_DIR}{data_file_name}')\n",
    "\n",
    "            y_pred = model.predict(X_valid) # predicted values\n",
    "            y_pred = correct_y_pred(y_pred)\n",
    "\n",
    "            # metrics (scores)\n",
    "            score_mae = mean_absolute_error(y_valid, y_pred)\n",
    "            score_mse = mean_squared_error(y_valid, y_pred)\n",
    "            score_rmse = np.sqrt(score_mse) \n",
    "            score_rmsle = rmsle(y_valid, y_pred)\n",
    "            score_r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "            feats = [str(feat) for feat in X_train.columns.tolist()] #eli5 needs string names for columns, so no columns with names like 1, 2, ....\n",
    "            model_params = str(model.get_params()) # model parameters\n",
    "            results_html_eli5, sorted_weights_eli5 = return_eli5(model, feats) #eli5 html and sorted list output\n",
    "            \n",
    "            # dictionary of all variables that are supposed to be logged\n",
    "            param_dict = {\n",
    "                'pipeline_name': pipeline_name,\n",
    "                'pipeline_steps': str(list(pipeline.named_steps.keys())),\n",
    "                'pipeline_comment': pipeline_comment,\n",
    "                'feats': str(feats), \n",
    "                'n_feats': len(X_train.columns.tolist()), ### added\n",
    "                'eli5_feats': str(sorted_weights_eli5),\n",
    "                'fs_method': 'no_selection',\n",
    "                'fs_param': '',\n",
    "                'fs_param_value': 0,\n",
    "                'model': model.__class__.__name__,\n",
    "                'model_custom_name': model_name,\n",
    "                'model_params': model_params,\n",
    "                'score_mae': score_mae,\n",
    "                'score_mse': score_mse,\n",
    "                'score_rmse': score_rmse,\n",
    "                'score_rmsle': score_rmsle,\n",
    "                'score_r2': score_r2,\n",
    "                'time_elapsed': end_time - start_time\n",
    "            }\n",
    "\n",
    "            models_heap += [param_dict] # add results to heap\n",
    "\n",
    "            # log into neptune if needed\n",
    "            if use_neptune:\n",
    "                score_metrics = [elem for elem in list(param_dict.keys()) if elem.startswith('score_')] + ['time_elapsed', 'fs_param_value', 'n_feats']\n",
    "                \n",
    "                # log values depending on their type (str or float)\n",
    "                for key, value in param_dict.items():\n",
    "                    if key not in score_metrics:\n",
    "                        neptune.log_text(key, value)\n",
    "                    else:\n",
    "                        neptune.log_metric(key, value)\n",
    "                \n",
    "                # save eli5 features\n",
    "                with open(f'{OUTPUT_DIR}eli5.html', 'w') as f:\n",
    "                    f.write(f'<html>{results_html_eli5.data}</html>')\n",
    "                neptune.log_artifact(f'{OUTPUT_DIR}eli5.html')\n",
    "\n",
    "            # add row into summary dataframe for local results\n",
    "            models_df = models_df.append(pd.DataFrame(param_dict, index = [0]))\n",
    "    \n",
    "\n",
    "    if use_fs:\n",
    "        best_experiments = heapq.nsmallest(5, models_heap, key = lambda x: x['score_rmsle']) # select top n element from heap\n",
    "        e += 1\n",
    "        \n",
    "        for experiment in best_experiments:\n",
    "            dataset = pd.read_csv(f'{OUTPUT_DIR}{experiment[\"pipeline_name\"]}.csv')\n",
    "            dataset = dataset.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x)) # prevent 'Do not support special JSON characters in feature name.' error in LightGBM\n",
    "            if 'Unnamed0' in dataset: del dataset['Unnamed0']\n",
    "            \n",
    "            model = pickle.load(open(f'{MODELS_DIR}{experiment[\"model_custom_name\"]}-{experiment[\"pipeline_name\"]}.model', 'rb'))\n",
    "            \n",
    "            for method in feature_selection_methods:\n",
    "\n",
    "\n",
    "                method_str = method[0].__name__\n",
    "                method_values = method[1]\n",
    "                method = method[0]\n",
    "\n",
    "                for method_value in method_values:\n",
    "                    feats = method(dataset, method_value)\n",
    "\n",
    "                    if feats is not None:\n",
    "                        X_train, X_valid, y_train, y_valid = make_X_y(dataset[feats])\n",
    "                    else:\n",
    "                        X_train, X_valid, y_train, y_valid = make_X_y(dataset)\n",
    "\n",
    "                    if use_neptune:\n",
    "                        neptune.create_experiment(f'{experiments_common_name}-{e}') # name of experiment\n",
    "                    \n",
    "                    e += 1\n",
    "                    start_time = time.time()\n",
    "                    model.fit(X_train, y_train)\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    y_pred = model.predict(X_valid) \n",
    "                    y_pred = correct_y_pred(y_pred)\n",
    "\n",
    "                    score_mae = mean_absolute_error(y_valid, y_pred)\n",
    "                    score_mse = mean_squared_error(y_valid, y_pred)\n",
    "                    score_rmse = np.sqrt(score_mse) \n",
    "                    score_rmsle = rmsle(y_valid, y_pred)\n",
    "                    score_r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "                    feats = [str(feat) for feat in X_train.columns.tolist()]\n",
    "                    model_params = str(model.get_params()) # model parameters\n",
    "                    results_html_eli5, sorted_weights_eli5 = return_eli5(model, feats)\n",
    "                    \n",
    "                    # dictionary of all variables that are supposed to be logged\n",
    "                    param_dict = {\n",
    "                        'pipeline_name': str(experiment['pipeline_name']),\n",
    "                        'pipeline_steps': str(experiment['pipeline_steps']),\n",
    "                        'pipeline_comment': str(experiment['pipeline_comment']),\n",
    "                        'feats': str(feats),\n",
    "                        'n_feats': len(feats),\n",
    "                        'eli5_feats': str(sorted_weights_eli5),\n",
    "                        'fs_method': method_str,\n",
    "                        'fs_param': inspect.getargspec(method)[0][-1],\n",
    "                        'fs_param_value': float(method_value),\n",
    "                        'model': str(experiment['model']),\n",
    "                        'model_custom_name': str(experiment['model_custom_name']),\n",
    "                        'model_params': str(experiment['model_params']),\n",
    "                        'score_mae': score_mae,\n",
    "                        'score_mse': score_mse,\n",
    "                        'score_rmse': score_rmse,\n",
    "                        'score_rmsle': score_rmsle,\n",
    "                        'score_r2': score_r2,\n",
    "                        'time_elapsed': end_time - start_time\n",
    "                    }\n",
    "\n",
    "                    # log into neptune if needed\n",
    "                    if use_neptune:\n",
    "                        score_metrics = [elem for elem in list(param_dict.keys()) if elem.startswith('score_')] + ['time_elapsed', 'fs_param_value', 'n_feats']\n",
    "                        \n",
    "                        # log values depending on their type (str or float)\n",
    "                        for key, value in param_dict.items():\n",
    "                            if key not in score_metrics:\n",
    "                                neptune.log_text(key, value)\n",
    "                            else:\n",
    "                                neptune.log_metric(key, value)\n",
    "\n",
    "                        # save eli5 features\n",
    "                        with open(f'{OUTPUT_DIR}eli5.html', 'w') as f:\n",
    "                            f.write(f'<html>{results_html_eli5.data}</html>')\n",
    "                        neptune.log_artifact(f'{OUTPUT_DIR}eli5.html')\n",
    "\n",
    "                    # add row into summary dataframe for local results\n",
    "                    models_df = models_df.append(pd.DataFrame(param_dict, index = [0]))\n",
    "        \n",
    "                    \n",
    "    models_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # end neptune instance\n",
    "    if use_neptune:\n",
    "        neptune.stop()\n",
    "    \n",
    "    return models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = run_experiments(pipelines, models, use_neptune = False, pickle_models= True, use_fs=True, dump_pickled_models_to_neptune= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***8. Additional (optional) test functions*** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run for single instance\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "test_model = xgb.XGBRegressor()\n",
    "run_single(df_train, basic_pipeline, test_model, None, metric=rmsle, show_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no_nlp.csv', 'RandomForest-no_nlp.model'),\n",
       " ('more_dummies_different_scaler_no_nlp.csv',\n",
       "  'RandomForest-more_dummies_different_scaler_no_nlp.model'),\n",
       " ('main_preprocess.csv', 'RandomForest-main_preprocess.model'),\n",
       " ('no_nlp_no_cos_sim.csv', 'RandomForest-no_nlp_no_cos_sim.model'),\n",
       " ('more_dummies_different_scaler_no_nlp_keep_3variables.csv',\n",
       "  'RandomForest-more_dummies_different_scaler_no_nlp_keep_3variables.model')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results_files(models_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_top_results_files('top_models.npy', models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results_df(models_df, 5).to_csv('best_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "423b8b96d4e1ec477b5c8920e05a523372dc7245eb6302a2ca5de114e24c04c2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
